---
title: "Exercises - random forests"
author: "Jan-Philipp Kolb"
date: "`r format(Sys.time(), '%d %B, %Y')`"
fontsize: 10pt
output:
  beamer_presentation: 
    colortheme: dolphin
    fig_height: 3
    fig_width: 5
    fig_caption: no
    fonttheme: structuresmallcapsserif
    highlight: haddock
    theme: Dresden
  pdf_document: 
    keep_tex: yes
    toc: yes
  slidy_presentation: 
    css: mycss.css
    keep_md: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,eval=T,message=F,warning=F)
```

## [Exercise: random forests](https://www.r-exercises.com/2016/12/29/intermediate-tree-1/)

<!--
1
-->

### Download and import example data

1) Download the Data from [**here**](http://www.r-exercises.com/wp-content/uploads/2016/11/adult.csv)
and read in the `adult.csv` file with `header=FALSE`. Store this in `dat`. Use `str()` command to see the dataframe. 
<!--
2

You are given the meta_data that goes with the CSV.
-->
2) Get the column names from the [**meta data**](https://github.com/Japhilko/machine_learning/raw/master/data/meta_cnames.Rdata) and add them to the data frame. Notice that ` dat` is ordered - V1,V2,V3,...  

<!--
http://www.r-exercises.com/wp-content/uploads/2016/11/adult_names.txt
-->

```{r,eval=F,echo=F}
cnames_dat <- c("age","workclass","fnlwgt","education",
               "education-num","marital-status","occupation",
               "relationhip","race","sex","capital-gain",
               "capital-loss","hours-per-week",
               "native-country","class")

save(cnames_dat,file="../data/meta_cnames.Rdata")
```

```{r,eval=F,echo=F}
pp<-scan("../data/meta.data",quiet=TRUE,skip=1)
```


<!--
As a side note, it is always best practice to use that to match and see if all the columns are read in correctly.
-->

### Get an overview of the data

3) Use the `table` command to get the distribution of the feature `class`.
4) Make a binary variable `class`.
5) Use the `cor()` command to see the corelation of all the numeric and integer columns including the class column. 
<!--
Remember that numbers close to 1 means high corelation and number close to 0 means low. 
This will give you a rough idea for feature selection
-->

## Solution: Download and import (I)
<!--
## Solution: random forests 
### Download
-->
### Solution Exercise 1: get the dataset

```{r,eval=F}
l1 <- "http://www.r-exercises.com/wp-content"
l2 <-"/uploads/2016/11/adult.csv"
link <- paste0(l1,l2)
dat <- read.csv(link,header=FALSE)
```

```{r,eval=F,echo=F}
save(dat,file="../data/adult.RData")
```

```{r,echo=F}
load("../data/adult.RData")
```


```{r}
str(dat)
```

<!--
## 'data.frame':	15916 obs. of  15 variables:
##  $ V1 : int  39 50 38 53 28 37 49 52 31 42 ...
##  $ V2 : Factor w/ 9 levels " ?"," Federal-gov",..: 8 7 5 5 5 5 5 7 5 5 ...
##  $ V3 : int  77516 83311 215646 234721 338409 284582 160187 209642 45781 159449 ...
##  $ V4 : Factor w/ 16 levels " 10th"," 11th",..: 10 10 12 2 10 13 7 12 13 10 ...
##  $ V5 : int  13 13 9 7 13 14 5 9 14 13 ...
##  $ V6 : Factor w/ 7 levels " Divorced"," Married-AF-spouse",..: 5 3 1 3 3 3 4 3 5 3 ...
##  $ V7 : Factor w/ 15 levels " ?"," Adm-clerical",..: 2 5 7 7 11 5 9 5 11 5 ...
##  $ V8 : Factor w/ 6 levels " Husband"," Not-in-family",..: 2 1 2 1 6 6 2 1 2 1 ...
##  $ V9 : Factor w/ 5 levels " Amer-Indian-Eskimo",..: 5 5 5 3 3 5 3 5 5 5 ...
##  $ V10: Factor w/ 2 levels " Female"," Male": 2 2 2 2 1 1 1 2 1 2 ...
##  $ V11: int  2174 0 0 0 0 0 0 0 14084 5178 ...
##  $ V12: int  0 0 0 0 0 0 0 0 0 0 ...
##  $ V13: int  40 13 40 40 40 40 16 45 50 40 ...
##  $ V14: Factor w/ 41 levels " ?"," Cambodia",..: 39 39 39 39 6 39 23 39 39 39 ...
##  $ V15: Factor w/ 2 levels " <=50K"," >50K": 1 1 1 1 1 1 1 2 2 2 ...


## Solution: random forests 

### Exercise 2  

-->

## Solution: Download and import (II)

### Solution Exercise 2 rename columns

```{r}
colnames(dat) <- c("age","workclass","fnlwgt","education",
               "education-num","marital-status","occupation",
               "relationhip","race","sex","capital-gain",
               "capital-loss","hours-per-week",
               "native-country","class")
```

```{r}
load("../data/meta_cnames.Rdata")
colnames(dat) <- cnames_dat
```



## Solution: Get overview

### Solution Exercise 3: get distribution


```{r}
table(dat$class)
```


<!--
##  <=50K   >50K 
##  12097   3819
-->

### Solution Exercise 4

- A binary variable class

```{r}
levels(dat$class) <- c(0,1)
dat$class <- as.numeric(dat$class)
```

```{r,eval=F,echo=F}
dat$class <- ifelse(dat$class==">50K", 1, 0)
```


## Solution Exercise 5

### Correlation of all numeric and integer variables

```{r}
(cormat <- cor(dat[,c(1,3,5,11,12,13,15)]))
```

## A `levelplot` of the correlation matrix

```{r}
lattice::levelplot(cormat)
```


<!--
##                        age       fnlwgt education-num capital-gain
## age             1.00000000 -0.079506361    0.02668698  0.066466487
## fnlwgt         -0.07950636  1.000000000   -0.04671504  0.000653693
## education-num   0.02668698 -0.046715043    1.00000000  0.117453069
## capital-gain    0.06646649  0.000653693    0.11745307  1.000000000
## capital-loss    0.06176551 -0.012139341    0.08090257 -0.031685331
## hours-per-week  0.05659864 -0.012345724    0.14528405  0.075715672
## class           0.22920766 -0.013067759    0.32856870  0.221049951
##                capital-loss hours-per-week       class
## age              0.06176551     0.05659864  0.22920766
## fnlwgt          -0.01213934    -0.01234572 -0.01306776
## education-num    0.08090257     0.14528405  0.32856870
## capital-gain    -0.03168533     0.07571567  0.22104995
## capital-loss     1.00000000     0.05439109  0.15366554
## hours-per-week   0.05439109     1.00000000  0.22544319
## class            0.15366554     0.22544319  1.00000000
-->




## [Exercise: random forests](https://www.r-exercises.com/2016/12/29/intermediate-tree-1/) 

### Split the dataset 

6) Split the dataset into Train and Test sample. You may use `caTools::sample.split()` and use the ratio as 0.7 and set the seed to be 1000. 
<!--
Make sure to install and load `caTools` package.
-->
7) Check the number of rows of Train and Test
8) We are ready to use decision tree in our dataset. Load the package `rpart` and `rpart.plot` 
<!--
If it is not installed, then use the `install.packages()` commmand.
-->
9) Use `rpart` to build the decision tree on the Train set. Include all features. Store this model in `dec`
10) Use `prp()` to plot the decision tree. 
<!--
If you get any error use `par(mar = rep(2, 4))` before the `prp()` command
-->


## Solutions

### Solution Exercise 6 - Split dataset

```{r}
dat$class <- as.factor(dat$class)
```


```{r}
set.seed(1000)
library(caTools)
split <- sample.split(dat$class, SplitRatio=0.8)
Train <- dat[split==TRUE,]
Test <- dat[split==FALSE,]
```

### Solution Exercise 7  - Number of rows

```{r}
nrow(Train)
nrow(Test)
```

## Solutions Exercise 

### Soltution erxercise 8 - load packages  

```{r}
library(rpart)
library(rpart.plot)
```

### Solution Exercise 9  - first model

```{r}
dec <- rpart(class~., data=Train)
```


## Solution Exercise 10 - plot the resulting tree

<!--
par(mar = rep(2, 4))
-->

```{r}
prp(dec)
```


## [Exercise](https://www.r-exercises.com/2017/01/05/intermediate-tree-2/) - predict and produce confusion matrix

11) use the `predict()` command to make predictions on the Train data. Set the method to `class`. Class returns classifications instead of probability scores. Store this prediction in `pred_dec`.
12) Create a [**confusion matrix**](https://towardsdatascience.com/understanding-confusion-matrix-a9ad42dcfd62) 
(4 different combinations of predicted and actual values - see figure below) and print it. 

[![](../slides/figure/confusionMatrix.png){height=50%}](https://towardsdatascience.com/understanding-confusion-matrix-a9ad42dcfd62)

## Exercises - accuracy 

13) What is the [**accuracy of the model**](https://en.wikipedia.org/wiki/Confusion_matrix) (ACC). Hint: all necessary information is in the confusion matrix.
14) What is the [**misclassification rate**](https://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/)? Hint: (FP+FN)/total

<!--
15) Lets say we want to find the baseline model to compare our prediction improvement. We create a base model using this code

```{r}
length(Test$class)
base <- rep(1,3183)
```

- Use the `table()` command to create a confusion matrix between the base and Test$class.
-->


## Exercises

<!--
6) What is the number difference between the confusion matrix accuracy of dec and base?
-->

15) Remember the `predict()` command in question 11. We will use the same mode and same command except we will set the method to “regression”. This gives us a probability estimates. Store this in pred_dec_reg

16) Load the `ROCR` package. Use the `prediction()`, `performance()` and `plot()` command to print the [**ROC curve**](https://en.wikipedia.org/wiki/Receiver_operating_characteristic. Use `pred_dec_reg` variable from Q7. You can also refer to the previous exercise to see the code.

17) `plot()` the same ROC curve but set `colorize=TRUE`

18) Comment on your findings using ROC curve and accuracy. Is it a good model? Did you notice that ROC `prediction()` command only takes probability predictions as one of its arguments. Why is that so?
<!--
## [Solution](https://www.r-exercises.com/2017/01/05/intermediate-tree-2-2/)

```{r,eval=F}
library(caTools)
colnames(dat)=c("age","workclass","fnlwgt","education",
"education-num","marital-status","occupation","relationhip",
"race","sex","capital-gain","capital-loss","hours-per-week",
"native-country","class")
dat$class <- ifelse(dat$class==" >50K", 1, 0)
dat$class <- as.factor(dat$class)
set.seed(1000)
```
-->

## Solution Exercise 11

### Split the dataset

```{r}
split <- caTools::sample.split(Y = dat$class, SplitRatio=0.7)
Train <- dat[split==TRUE,]
Test <- dat[split==FALSE,]
```

```{r}
library(rpart)
library(rpart.plot)
```

```{r,eval=F}
dec <- rpart(class~., data=Train)
```

```{r,eval=F,echo=F}
save(dec,file="../data/ml_rf_dec.RData")
```

```{r,echo=F}
load("../data/ml_rf_dec.RData")
```



```{r}
pred_dec <- predict(dec,newdata = Test,type="class")
```

## Solutions 

### Exercise 12 - Confusion matrix

```{r}
(confmat <- table(Test$class,pred_dec))
```

<!--
##    pred_dec
##        0    1
##   0 2345   74
##   1  400  364
-->

### Solution Exercise 13 - model accuracy

```{r}
(confmat[1,1] + confmat[2,2])/(sum(confmat))
```

<!--

(2345+364)/(2345+364+400+74)

das oben drüber stimmt vermutlich nicht

## [1] 0.8510839
-->

### Solution Exercise 14 - misclassification error

```{r}
mean(as.factor(Test$class)!=pred_dec)
```

<!--
https://blog.revolutionanalytics.com/2016/03/com_class_eval_metrics_r.html
-->

<!--
## [1] 0.1489161
-->

<!--
## Solution Exercise 15

```{r}
length(Test$class)
```
-->

<!--
## [1] 3183
-->

<!--
```{r}
base <- rep(1,nrow(Test))
table(Test$class,base)
```
-->

<!--
##    base
##        1
##   0 2419
##   1  764
-->

## Further solutions

<!--
### Solution Exercise 6

0.54
-->

### Solution Exercise 15 - Make prediction

```{r}
pred_dec_reg <- predict(dec,newdata = Test,type="prob")
```


### Solution Exercise 16 - ROC Curve

```{r,eval=F,echo=F}
install.packages("ROCR")
```


```{r}
library(ROCR)
pred <- prediction(predictions=as.numeric(pred_dec_reg[,2]),
                   Test$class)
perf <- performance(pred,"tpr","fpr")
```

```{r,eval=F}
plot(perf)
```

## Performance plot

```{r,echo=F}
plot(perf)
```


## Solution Exercise 17

```{r}
plot(perf,colorize=TRUE)
```

## Solution Exercise 18

- It is a good model. The initial accuracy is 0.85 which is pretty good. 
- The ROC curve is also leaning more towards the true positive side which is also a good sign. ROC `prediction()` command takes probability score predictions because it is used to give a visual representation of a range of threshold values. 
- We can use ROC also to interpret what threshold value to chose and decide the ratio of true positive to false positives based on the problem at hand. That is for another exercise


<!--
https://www.r-exercises.com/2017/01/05/intermediate-tree-2/
https://github.com/eugeneyan/Statistical-Learning/blob/master/Chapter%208%20Exercises.R

https://rstudio-pubs-static.s3.amazonaws.com/245066_f7b5962e8ab84594829b84f06ced39b6.html
-->