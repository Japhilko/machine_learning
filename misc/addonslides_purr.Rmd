---
title: "The packages magrittr, dplyr and purrr"
author: "Jan-Philipp Kolb"
date: "28 5 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 

```{r}
library(magrittr)
```


## Create or transform variables


```{r}
?dplyr::mutate
```

## Apply a function to each element of a vector

```{r}
?purrr::map_dbl
```

## Arrange rows by variables

```{r}
?dplyr::arrange
```

```{r}
dplyr::arrange(mtcars, cyl, disp)
```

## Select top (or bottom) n rows (by value)

```{r}
?dplyr::top_n
```

```{r}
mtcars %>% dplyr::top_n(-2)
```



## `mtcars` example

- Target: predict the miles per gallon a car will drive in average 
- Independent variables: cylinders (`cyl`) and horsepower (`hp`). 
- All observations go through the tree, are assessed at a node, and proceed to the left if the answer is "yes"" or to the right if the answer is "no". 
- E.g., all observations that have 6 or 8 cylinders go to the left branch, all other proceed to the right branch. 
- Next, the left branch is further partitioned by horsepower. 
- Those 6 or 8 cylinder observations with horsepower equal to or greater than 192 proceed to the left branch; those with less than 192 hp proceed to the right. 
- These branches lead to terminal nodes or leafs which contain our predicted response value. 
- All cars that do not have 6 or 8 cylinders (far right branch) average 27 mpg. 
- All cars that have 6 or 8 cylinders and have more than 192 hp (far left branch) average 13 mpg.

## Predicting `mpg` based on `cyl` and `hp`.

![](figure/ex_regression_tree.png)

## The package `rpart` 

- `rpart` - recursive partitioning and regression trees

### The `kyphosis` dataset 

- Data on Children who have had Corrective Spinal Surgery
- The German word is Rundrücken

```{r,eval=F}
?kyphosis
```

<!--
vertebrae - Wirbel
-->


- Number - the number of vertebrae involved
- Start - the number of the first (topmost) vertebra operated on.

```{r}
kable(head(kyphosis))
```


## [Classification Tree example](https://www.statmethods.net/advstats/cart.html)

<!--
https://www.statmethods.net/advstats/cart.html
-->

```{r}
fit <- rpart(Kyphosis ~ Age + Number + Start,
   method="class", data=kyphosis)
```

```{r}
printcp(fit) # display the results 
```


```{r}
plotcp(fit) 
```


```{r}
summary(fit)
```

```{r}
# plot tree 
plot(fit, uniform=TRUE, 
   main="Classification Tree for Kyphosis")
text(fit, use.n=TRUE, all=TRUE, cex=.8)
```

```{r,eval=F}
# create attractive postscript plot of tree 
post(fit, file = "D:/Daten/GitHub/machine_learning/slides/figure/tree.ps", 
   title = "Classification Tree for Kyphosis")
```


## `h2o` package

```{r,eval=F,echo=F}
install.packages("h2o")
```



```{r,eval=F}
# http://uc-r.github.io/regularized_regression
library(h2o)
h2o.init()

# convert data to h2o object
ames_h2o <- ames_train %>%
  mutate(Sale_Price_log = log(Sale_Price)) %>%
  as.h2o()

# set the response column to Sale_Price_log
response <- "Sale_Price_log"

# set the predictor names
predictors <- setdiff(colnames(ames_train), "Sale_Price")

# try using the `alpha` parameter:
# train your model, where you specify alpha
ames_glm <- h2o.glm(
  x = predictors, 
  y = response, 
  training_frame = ames_h2o,
  nfolds = 10,
  keep_cross_validation_predictions = TRUE,
  alpha = .25
  )

# print the mse for the validation data
print(h2o.mse(ames_glm, xval = TRUE))

# grid over `alpha`
# select the values for `alpha` to grid over
hyper_params <- list(
  alpha = seq(0, 1, by = .1),
  lambda = seq(0.0001, 10, length.out = 10)
  )

# this example uses cartesian grid search because the search space is small
# and we want to see the performance of all models. For a larger search space use
# random grid search instead: {'strategy': "RandomDiscrete"}

# build grid search with previously selected hyperparameters
grid <- h2o.grid(
  x = predictors, 
  y = response, 
  training_frame = ames_h2o, 
  nfolds = 10,
  keep_cross_validation_predictions = TRUE,
  algorithm = "glm",
  grid_id = "ames_grid", 
  hyper_params = hyper_params,
  search_criteria = list(strategy = "Cartesian")
  )

# Sort the grid models by mse
sorted_grid <- h2o.getGrid("ames_grid", sort_by = "mse", decreasing = FALSE)
sorted_grid

# grab top model id
best_h2o_model <- sorted_grid@model_ids[[1]]
best_model <- h2o.getModel(best_h2o_model)
```



<!--
ames_lasso, s
-->




## [Algorithm selection](https://elitedatascience.com/algorithm-selection)

- Unfortunately, decision trees suffer from a major flaw. 
- If you allow them to grow limitlessly, they can completely "memorize" the training data, just from creating more and more and more branches.
- As a result, individual unconstrained decision trees are very prone to being overfit.



## [Three datasets to build a model](https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets)

- In machine learning the model is initially fit on a training dataset that is a set of examples used to fit the parameters.

-  the fitted model is used to predict the responses for the observations in a second dataset called the validation dataset.


```{r}
library(ROCR)
data(ROCR.simple)
pred <- prediction(ROCR.simple$predictions,ROCR.simple$labels)
```


<!--
https://gerardnico.com/data_mining/error_rate
-->


## The plotted error rate

```{r,echo=F}
sqrtm1 <- sqrt(m1$mse[which.min(m1$mse)])
```


- The plotted error rate above is based on the OOB sample error and can be accessed directly at 

```{r,eval=F}
m1$mse
```

- The lowest error rate, is 344 trees providing an average home sales price error of  `r sqrtm1` Dollar.

```{r}
which.min(m1$mse)
sqrt(m1$mse[which.min(m1$mse)])
```


<!--
if we did not want to use the OOB samples. 
valid_split <- valid_split%>% na.omit()
-->

<!--
## A validation set to measure predictive accuracy

- `randomForest` also allows us to use a validation set to measure predictive accuracy 
- Here we split our training set further to create a training and validation set. 
- The validation data is in `xtest` and `ytest`.

```{r,eval=F}
set.seed(123)
valid_split <- initial_split(ames_train, .8)
# training data
ames_train_v2 <- analysis(valid_split)
# validation data
ames_valid <- rsample::assessment(valid_split)
x_test <- ames_valid[setdiff(names(ames_valid), "Sale_Price")]
y_test <- ames_valid$Sale_Price
```


## Run the model   

- With the command `randomForest`

```{r,eval=F}
rf_oob_comp <- randomForest(formula=Sale_Price ~ .,
  data=ames_train_v2,xtest = x_test,ytest=y_test)
```

```{r,eval=F,echo=F}
save(rf_oob_comp,file="../data/ml_rf_oob_comp.RData")
```

```{r,echo=F}
load("../data/ml_rf_oob_comp.RData")
```

### extract OOB & validation errors

```{r}
oob <- sqrt(rf_oob_comp$mse)
validation <- sqrt(rf_oob_comp$test$mse)
```



## compare error rates

- Extract OOB & validation errors

```{r,eval=F}
tibble::tibble(
  `Out of Bag Error` = oob,
  `Test error` = validation,
  ntrees = 1:rf_oob_comp$ntree
) %>%
  gather(Metric, RMSE, -ntrees) %>%
  ggplot(aes(ntrees, RMSE, color = Metric)) +
  geom_line() +
  scale_y_continuous(labels = scales::dollar) +
  xlab("Number of trees")
```

## 

```{r,echo=F}
## Compare error rates
tibble::tibble(
  `Out of Bag Error` = oob,
  `Test error` = validation,
  ntrees = 1:rf_oob_comp$ntree
) %>%
  gather(Metric, RMSE, -ntrees) %>%
  ggplot(aes(ntrees, RMSE, color = Metric)) +
  geom_line() +
  scale_y_continuous(labels = scales::dollar) +
  xlab("Number of trees")
```

-->


## Annex 


### Scoring models - metrics

- Many packages do not keep track of which observations were part of the OOB sample for a given tree and which were not. 
- If you are comparing multiple models, you’d want to score each on the same validation set to compare performance. 
- It is possible to compute certain metrics such as [**root mean squared logarithmic error**](https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/loss-functions/mean-squared-logarithmic-error) (RMSLE) on the OOB sample, but it is not built in to all packages. 
- So if you want to compare multiple models or use a slightly less traditional loss function you will likely want to still perform cross validation.


<!--
https://maths-people.anu.edu.au/~johnm/courses/r/exercises/pdf/r-exercises.pdf
https://www.hackerearth.com/practice/machine-learning/machine-learning-algorithms/tutorial-random-forest-parameter-tuning-r/tutorial/
-->

  


